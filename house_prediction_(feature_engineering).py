# -*- coding: utf-8 -*-
"""House Prediction (Feature Engineering).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1B5jhUGGIQF2yqP4FinJ7N59XXhqc6A2-
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

pd.pandas.set_option('display.max_columns', None)

dataset=pd.read_csv('/train.csv')
dataset.head()

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(dataset,dataset['SalePrice'],test_size=0.1,random_state=0)

X_train.shape, X_test.shape

#MISSING VALUES
features_nan=[feature for feature in dataset.columns if dataset[feature].isnull().sum()>1 and dataset[feature].dtypes=='O']

for feature in features_nan:
    print("{}: {}% missing values".format(feature,np.round(dataset[feature].isnull().mean(),4)))

def replace_cat_feature(dataset,features_nan):
  data=dataset.copy()
  data[features_nan]=data[features_nan].fillna('Missing')
  return data

dataset=replace_cat_feature(dataset,features_nan)  
dataset[features_nan].isnull().sum()

dataset.head()

numerical_with_nan=[feature for feature in dataset.columns if dataset[feature].isnull().sum()>1 and dataset[feature].dtypes !='O']

for feature in numerical_with_nan:
  print("{}: {}% missing  value".format(feature,np.around(dataset[feature].isnull().mean(),4)))

for feature in numerical_with_nan:
  median_value=dataset[feature].median()

  dataset[feature+'nan']=np.where(dataset[feature].isnull(),1,0)
  dataset[feature].fillna(median_value,inplace=True)

dataset[numerical_with_nan].isnull().sum()

dataset.head(50)

for feature in ['YearBuilt','YearRemodAdd','GarageYrBlt']:
  dataset[feature]=dataset['YrSold']-dataset[feature]

dataset.head()

dataset[['YearBuilt','YearRemodAdd','GarageYrBlt']].head()

#NUMERICAL VARIABLES
import numpy as np
num_features=['LotFrontage', 'LotArea', '1stFlrSF', 'GrLivArea', 'SalePrice']

for feature in num_features:
  dataset[feature]=np.log(dataset[feature])

dataset.head()

#HANDLING RARE CATEGORICAL FEATURE
categorical_features=[feature for feature in dataset.columns if dataset[feature].dtype=='O']
categorical_features

for feature in categorical_features:
  temp = dataset.groupby(feature)['SalePrice'].count()/len(dataset)
  temp_df=temp[temp>0.01].index
  dataset[feature]=np.where(dataset[feature].isin(temp_df),dataset[feature],'Rare_var')

dataset.head(100)

for feature in categorical_features:
    labels_ordered=dataset.groupby([feature])['SalePrice'].mean().sort_values().index
    labels_ordered={k:i for i,k in enumerate(labels_ordered,0)}
    dataset[feature]=dataset[feature].map(labels_ordered)

dataset.head(10)

scaling_feature=[feature for feature in dataset.columns if feature not in ['Id','SalePerice'] ]
len(scaling_feature)

scaling_feature

dataset.head()

feature_scale=[feature for feature in dataset.columns if feature not in ['Id','SalePrice']]

from sklearn.preprocessing import MinMaxScaler
scaler=MinMaxScaler()
scaler.fit(dataset[feature_scale])

scaler.transform(dataset[feature_scale])

data = pd.concat([dataset[['Id', 'SalePrice']].reset_index(drop=True),
                    pd.DataFrame(scaler.transform(dataset[feature_scale]), columns=feature_scale)],
                    axis=1)

data.head()

data.to_csv('X_train.csv',index='False')

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
# %matplotlib inline

from sklearn.linear_model import Lasso
from sklearn.feature_selection import SelectFromModel

pd.pandas.set_option('display.max_columns',None)

dataset=pd.read_csv('X_train.csv')

dataset.head()

y_train=dataset[['SalePrice']]
X_train=dataset.drop(['Id','SalePrice'],axis=1)

feature_sel_model = SelectFromModel(Lasso(alpha=0.05, random_state=0))
feature_sel_model.fit(X_train,y_train)

feature_sel_model.get_support()

# let's print the number of total and selected features

# this is how we can make a list of the selected features
selected_feat = X_train.columns[(feature_sel_model.get_support())]

# let's print some stats
print('total features: {}'.format((X_train.shape[1])))
print('selected features: {}'.format(len(selected_feat)))
print('features with coefficients shrank to zero: {}'.format(
    np.sum(feature_sel_model.estimator_.coef_ == 0)))

selected_feat

X_train=X_train[selected_feat]

X_train.head()

